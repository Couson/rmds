{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages you need\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Packages for dashboard\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.express as px\n",
    "\n",
    "# Packages for handling dates\n",
    "from dateutil import parser\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "# Add more cleaning procedures if needed\n",
    "\n",
    "restaurant_df=pd.read_excel(r'E:\\LMU\\rmds_lab\\competition_2021\\Q3_competition\\sample_dashboard\\inputs\\Q3_competition_detail_dataset.xlsx')\n",
    "restaurant_df['latitude']=restaurant_df['latitude'].astype('float')\n",
    "restaurant_df['longitude']=restaurant_df['longitude'].astype('float')\n",
    "restaurant_df=restaurant_df.reset_index()\n",
    "restaurant_df=restaurant_df.drop('index',axis=1)\n",
    "restaurant_df['Price'] = restaurant_df['price'].apply(lambda x: len(str(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>is_claimed</th>\n",
       "      <th>is_closed</th>\n",
       "      <th>phone</th>\n",
       "      <th>review_count</th>\n",
       "      <th>categories01</th>\n",
       "      <th>categories02</th>\n",
       "      <th>categories03</th>\n",
       "      <th>rating</th>\n",
       "      <th>...</th>\n",
       "      <th>city</th>\n",
       "      <th>address</th>\n",
       "      <th>restaurant_url</th>\n",
       "      <th>image_url</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>photos</th>\n",
       "      <th>cross_streets</th>\n",
       "      <th>Price</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nzgC5hhlnSq2DYbJbtH5MQ</td>\n",
       "      <td>Foxy's Landing &amp; Restaurant</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.661949e+10</td>\n",
       "      <td>52</td>\n",
       "      <td>Breakfast_brunch</td>\n",
       "      <td>Tradamerican</td>\n",
       "      <td>Nan</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Lancaster</td>\n",
       "      <td>['4555 W Avenue G', 'Lancaster, CA 93536']</td>\n",
       "      <td>https://www.yelp.com/biz/foxys-landing-and-res...</td>\n",
       "      <td>https://s3-media1.fl.yelpcdn.com/bphoto/LooWtz...</td>\n",
       "      <td>34.738829</td>\n",
       "      <td>-118.216215</td>\n",
       "      <td>['https://s3-media1.fl.yelpcdn.com/bphoto/LooW...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Lancaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i-2aG9_PQBEy7LrsRv0Ivg</td>\n",
       "      <td>Mosman's Steakhouse</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.661949e+10</td>\n",
       "      <td>63</td>\n",
       "      <td>Bars</td>\n",
       "      <td>Steak</td>\n",
       "      <td>Nan</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Lancaster</td>\n",
       "      <td>['46645 W 60th W', 'Lancaster, CA 93536']</td>\n",
       "      <td>https://www.yelp.com/biz/mosmans-steakhouse-la...</td>\n",
       "      <td>https://s3-media3.fl.yelpcdn.com/bphoto/JJ3mkC...</td>\n",
       "      <td>34.730580</td>\n",
       "      <td>-118.238360</td>\n",
       "      <td>['https://s3-media3.fl.yelpcdn.com/bphoto/JJ3m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Lancaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DJoeogRsOW5s9MzgveHQ2A</td>\n",
       "      <td>El Tamarindo</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.661723e+10</td>\n",
       "      <td>11</td>\n",
       "      <td>Salvadoran</td>\n",
       "      <td>Nan</td>\n",
       "      <td>Nan</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Lancaster</td>\n",
       "      <td>['551 W Ave I', 'Ste E', 'Lancaster, CA 93534']</td>\n",
       "      <td>https://www.yelp.com/biz/el-tamarindo-lancaste...</td>\n",
       "      <td>https://s3-media1.fl.yelpcdn.com/bphoto/UMSkfH...</td>\n",
       "      <td>34.707469</td>\n",
       "      <td>-118.146286</td>\n",
       "      <td>['https://s3-media1.fl.yelpcdn.com/bphoto/UMSk...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Lancaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hwWfv3sSxV3a47UAdSVT5w</td>\n",
       "      <td>Subway</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.661730e+10</td>\n",
       "      <td>13</td>\n",
       "      <td>Sandwiches</td>\n",
       "      <td>Nan</td>\n",
       "      <td>Nan</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Lancaster</td>\n",
       "      <td>['1821 W Ave I', 'Unit 103', 'Lancaster, CA 93...</td>\n",
       "      <td>https://www.yelp.com/biz/subway-lancaster-106?...</td>\n",
       "      <td>https://s3-media3.fl.yelpcdn.com/bphoto/4Yo7Ea...</td>\n",
       "      <td>34.705218</td>\n",
       "      <td>-118.164180</td>\n",
       "      <td>['https://s3-media3.fl.yelpcdn.com/bphoto/4Yo7...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Lancaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TxU0fwF2N2nVhCpzokc1Pg</td>\n",
       "      <td>Little Caesars</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.661946e+10</td>\n",
       "      <td>54</td>\n",
       "      <td>Pizza</td>\n",
       "      <td>Nan</td>\n",
       "      <td>Nan</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Lancaster</td>\n",
       "      <td>['1841 W Ave I', 'Bldg 2, Ste D', 'Lancaster, ...</td>\n",
       "      <td>https://www.yelp.com/biz/little-caesars-lancas...</td>\n",
       "      <td>https://s3-media2.fl.yelpcdn.com/bphoto/-Fz1W5...</td>\n",
       "      <td>34.705100</td>\n",
       "      <td>-118.164870</td>\n",
       "      <td>['https://s3-media2.fl.yelpcdn.com/bphoto/-Fz1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Lancaster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                         name  is_claimed  is_closed  \\\n",
       "0  nzgC5hhlnSq2DYbJbtH5MQ  Foxy's Landing & Restaurant        True      False   \n",
       "1  i-2aG9_PQBEy7LrsRv0Ivg          Mosman's Steakhouse        True      False   \n",
       "2  DJoeogRsOW5s9MzgveHQ2A                 El Tamarindo        True      False   \n",
       "3  hwWfv3sSxV3a47UAdSVT5w                       Subway        True      False   \n",
       "4  TxU0fwF2N2nVhCpzokc1Pg               Little Caesars        True      False   \n",
       "\n",
       "          phone  review_count      categories01  categories02 categories03  \\\n",
       "0  1.661949e+10            52  Breakfast_brunch  Tradamerican          Nan   \n",
       "1  1.661949e+10            63              Bars         Steak          Nan   \n",
       "2  1.661723e+10            11        Salvadoran           Nan          Nan   \n",
       "3  1.661730e+10            13        Sandwiches           Nan          Nan   \n",
       "4  1.661946e+10            54             Pizza           Nan          Nan   \n",
       "\n",
       "   rating  ...       city                                            address  \\\n",
       "0     4.0  ...  Lancaster         ['4555 W Avenue G', 'Lancaster, CA 93536']   \n",
       "1     3.5  ...  Lancaster          ['46645 W 60th W', 'Lancaster, CA 93536']   \n",
       "2     3.5  ...  Lancaster    ['551 W Ave I', 'Ste E', 'Lancaster, CA 93534']   \n",
       "3     2.5  ...  Lancaster  ['1821 W Ave I', 'Unit 103', 'Lancaster, CA 93...   \n",
       "4     1.5  ...  Lancaster  ['1841 W Ave I', 'Bldg 2, Ste D', 'Lancaster, ...   \n",
       "\n",
       "                                      restaurant_url  \\\n",
       "0  https://www.yelp.com/biz/foxys-landing-and-res...   \n",
       "1  https://www.yelp.com/biz/mosmans-steakhouse-la...   \n",
       "2  https://www.yelp.com/biz/el-tamarindo-lancaste...   \n",
       "3  https://www.yelp.com/biz/subway-lancaster-106?...   \n",
       "4  https://www.yelp.com/biz/little-caesars-lancas...   \n",
       "\n",
       "                                           image_url   latitude   longitude  \\\n",
       "0  https://s3-media1.fl.yelpcdn.com/bphoto/LooWtz...  34.738829 -118.216215   \n",
       "1  https://s3-media3.fl.yelpcdn.com/bphoto/JJ3mkC...  34.730580 -118.238360   \n",
       "2  https://s3-media1.fl.yelpcdn.com/bphoto/UMSkfH...  34.707469 -118.146286   \n",
       "3  https://s3-media3.fl.yelpcdn.com/bphoto/4Yo7Ea...  34.705218 -118.164180   \n",
       "4  https://s3-media2.fl.yelpcdn.com/bphoto/-Fz1W5...  34.705100 -118.164870   \n",
       "\n",
       "                                              photos  cross_streets  Price  \\\n",
       "0  ['https://s3-media1.fl.yelpcdn.com/bphoto/LooW...            NaN      2   \n",
       "1  ['https://s3-media3.fl.yelpcdn.com/bphoto/JJ3m...            NaN      2   \n",
       "2  ['https://s3-media1.fl.yelpcdn.com/bphoto/UMSk...            NaN      1   \n",
       "3  ['https://s3-media3.fl.yelpcdn.com/bphoto/4Yo7...            NaN      1   \n",
       "4  ['https://s3-media2.fl.yelpcdn.com/bphoto/-Fz1...            NaN      1   \n",
       "\n",
       "        City  \n",
       "0  Lancaster  \n",
       "1  Lancaster  \n",
       "2  Lancaster  \n",
       "3  Lancaster  \n",
       "4  Lancaster  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning city names\n",
    "# Add more cleaning procedures if needed\n",
    "\n",
    "restaurant_df['City'] = restaurant_df.city.apply(lambda x: x.strip().lower())\n",
    "\n",
    "# Column name changed\n",
    "restaurant_df['City'] = restaurant_df.City.apply(lambda x: x[:-2] if x[-2:]=='ca' else x)\n",
    "restaurant_df['City'] = restaurant_df.City.apply(lambda x: ' '.join(x.split()))\n",
    "restaurant_df['City'] = restaurant_df.City.replace('lost angeles', 'los angeles')\n",
    "restaurant_df['City'] = restaurant_df.City.replace('longbeach', 'long beach')\n",
    "restaurant_df['City'] = restaurant_df.City.replace('rowland hghts', 'rowland heights')\n",
    "restaurant_df['City'] = restaurant_df.City.replace('rowland heightes', 'rowland heights')\n",
    "restaurant_df['City'] = restaurant_df.City.replace('santa fe spring', 'santa fe springs')\n",
    "restaurant_df['City'] = restaurant_df.City.replace('shermanoaks', 'sherman oaks')\n",
    "restaurant_df['City'] = restaurant_df.City.replace('canyon cntry', 'canyon country')\n",
    "restaurant_df['City'] = restaurant_df.City.replace('studiocity', 'studio city')\n",
    "restaurant_df['City'] = restaurant_df.City.replace('santa moni', 'santa monica')\n",
    "\n",
    "# Set up capital letters for first letter\n",
    "restaurant_df['City'] = restaurant_df.City.apply(lambda x: str(x)[0].upper()+ str(x)[1:])\n",
    "restaurant_df['categories01'] = restaurant_df.categories01.apply(lambda x: str(x)[0].upper()+ str(x)[1:])\n",
    "restaurant_df['categories02'] = restaurant_df.categories02.apply(lambda x: str(x)[0].upper()+ str(x)[1:])\n",
    "restaurant_df['categories03'] = restaurant_df.categories03.apply(lambda x: str(x)[0].upper()+ str(x)[1:])\n",
    "\n",
    "# Using this file for map and bar chart\n",
    "map_df = restaurant_df.copy()\n",
    "bar_df = restaurant_df.copy()\n",
    "map_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beverly hills', 'Culver city', 'Glendale', 'Huntington park', 'Lancaster', 'Long beach', 'Palmdale', 'Pasadena', 'Santa monica', 'South gate']\n",
      "['Burgers', 'Chinese', 'Hotdogs', 'Japanese', 'Korean', 'Mexican', 'Newamerican', 'Pizza', 'Sandwiches', 'Sushi']\n"
     ]
    }
   ],
   "source": [
    "# Create city_list\n",
    "\n",
    "city_list = restaurant_df.groupby('City').count().sort_values(by='id',ascending=False)[:10].index.to_list()\n",
    "city_list.remove('Los angeles')\n",
    "city_list.append('Pasadena')\n",
    "city_list.sort()\n",
    "\n",
    "\n",
    "# Create category_list\n",
    "\n",
    "category_list = restaurant_df.groupby('categories01').count().sort_values(by='id',ascending=False)[:10].index.to_list()\n",
    "category_list.sort()\n",
    "print(city_list)\n",
    "print(category_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_time_created</th>\n",
       "      <th>name</th>\n",
       "      <th>is_claimed</th>\n",
       "      <th>is_closed</th>\n",
       "      <th>phone</th>\n",
       "      <th>review_count</th>\n",
       "      <th>...</th>\n",
       "      <th>city</th>\n",
       "      <th>address</th>\n",
       "      <th>restaurant_url</th>\n",
       "      <th>image_url</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>photos</th>\n",
       "      <th>cross_streets</th>\n",
       "      <th>Price</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cal0Wpupxj9c_AV7WzDXsw</td>\n",
       "      <td>AyueC5Vq_5lUKJFqSzXWWw</td>\n",
       "      <td>Slightly turned off by the hostess. She wasn't...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2021-07-13 15:01:59</td>\n",
       "      <td>GRANVILLE</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.424523e+10</td>\n",
       "      <td>1610</td>\n",
       "      <td>...</td>\n",
       "      <td>West Hollywood</td>\n",
       "      <td>['8701 Beverly Blvd', 'West Hollywood, CA 90048']</td>\n",
       "      <td>https://www.yelp.com/biz/granville-west-hollyw...</td>\n",
       "      <td>https://s3-media2.fl.yelpcdn.com/bphoto/EuQ6eU...</td>\n",
       "      <td>34.077130</td>\n",
       "      <td>-118.380680</td>\n",
       "      <td>['https://s3-media2.fl.yelpcdn.com/bphoto/EuQ6...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>West hollywood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cal0Wpupxj9c_AV7WzDXsw</td>\n",
       "      <td>yaH4AmHUz9b3Ywv4VtvU5g</td>\n",
       "      <td>Wish I would have known about no brunch at the...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2021-07-06 13:50:42</td>\n",
       "      <td>GRANVILLE</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.424523e+10</td>\n",
       "      <td>1610</td>\n",
       "      <td>...</td>\n",
       "      <td>West Hollywood</td>\n",
       "      <td>['8701 Beverly Blvd', 'West Hollywood, CA 90048']</td>\n",
       "      <td>https://www.yelp.com/biz/granville-west-hollyw...</td>\n",
       "      <td>https://s3-media2.fl.yelpcdn.com/bphoto/EuQ6eU...</td>\n",
       "      <td>34.077130</td>\n",
       "      <td>-118.380680</td>\n",
       "      <td>['https://s3-media2.fl.yelpcdn.com/bphoto/EuQ6...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>West hollywood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cal0Wpupxj9c_AV7WzDXsw</td>\n",
       "      <td>YiuFLFWsrP92_QWa-d2W2Q</td>\n",
       "      <td>I had an amazing experience at Granville.\\n\\nw...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2021-08-09 21:06:24</td>\n",
       "      <td>GRANVILLE</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.424523e+10</td>\n",
       "      <td>1610</td>\n",
       "      <td>...</td>\n",
       "      <td>West Hollywood</td>\n",
       "      <td>['8701 Beverly Blvd', 'West Hollywood, CA 90048']</td>\n",
       "      <td>https://www.yelp.com/biz/granville-west-hollyw...</td>\n",
       "      <td>https://s3-media2.fl.yelpcdn.com/bphoto/EuQ6eU...</td>\n",
       "      <td>34.077130</td>\n",
       "      <td>-118.380680</td>\n",
       "      <td>['https://s3-media2.fl.yelpcdn.com/bphoto/EuQ6...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>West hollywood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jVYU9iXvBMiC2A4H12Azfg</td>\n",
       "      <td>VyKvwjOuJxKWiLlyzsqQ_A</td>\n",
       "      <td>Photo dump from dinner on Aug 8th. Literally c...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2021-08-09 13:01:09</td>\n",
       "      <td>AOC</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.310860e+10</td>\n",
       "      <td>2362</td>\n",
       "      <td>...</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>['8700 W 3rd St', 'Los Angeles, CA 90048']</td>\n",
       "      <td>https://www.yelp.com/biz/aoc-los-angeles?adjus...</td>\n",
       "      <td>https://s3-media4.fl.yelpcdn.com/bphoto/UGnsMC...</td>\n",
       "      <td>34.073416</td>\n",
       "      <td>-118.381928</td>\n",
       "      <td>['https://s3-media4.fl.yelpcdn.com/bphoto/UGns...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Los angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jVYU9iXvBMiC2A4H12Azfg</td>\n",
       "      <td>D0-MjyINO2u9IRmf1opaUQ</td>\n",
       "      <td>I've had this place bookmarked on my Yelp for ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2021-07-17 16:28:47</td>\n",
       "      <td>AOC</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.310860e+10</td>\n",
       "      <td>2362</td>\n",
       "      <td>...</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>['8700 W 3rd St', 'Los Angeles, CA 90048']</td>\n",
       "      <td>https://www.yelp.com/biz/aoc-los-angeles?adjus...</td>\n",
       "      <td>https://s3-media4.fl.yelpcdn.com/bphoto/UGnsMC...</td>\n",
       "      <td>34.073416</td>\n",
       "      <td>-118.381928</td>\n",
       "      <td>['https://s3-media4.fl.yelpcdn.com/bphoto/UGns...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Los angeles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id               review_id  \\\n",
       "0  cal0Wpupxj9c_AV7WzDXsw  AyueC5Vq_5lUKJFqSzXWWw   \n",
       "1  cal0Wpupxj9c_AV7WzDXsw  yaH4AmHUz9b3Ywv4VtvU5g   \n",
       "2  cal0Wpupxj9c_AV7WzDXsw  YiuFLFWsrP92_QWa-d2W2Q   \n",
       "3  jVYU9iXvBMiC2A4H12Azfg  VyKvwjOuJxKWiLlyzsqQ_A   \n",
       "4  jVYU9iXvBMiC2A4H12Azfg  D0-MjyINO2u9IRmf1opaUQ   \n",
       "\n",
       "                                         review_text  review_rating  \\\n",
       "0  Slightly turned off by the hostess. She wasn't...            3.0   \n",
       "1  Wish I would have known about no brunch at the...            3.0   \n",
       "2  I had an amazing experience at Granville.\\n\\nw...            5.0   \n",
       "3  Photo dump from dinner on Aug 8th. Literally c...            5.0   \n",
       "4  I've had this place bookmarked on my Yelp for ...            2.0   \n",
       "\n",
       "   review_time_created       name  is_claimed  is_closed         phone  \\\n",
       "0  2021-07-13 15:01:59  GRANVILLE        True      False  1.424523e+10   \n",
       "1  2021-07-06 13:50:42  GRANVILLE        True      False  1.424523e+10   \n",
       "2  2021-08-09 21:06:24  GRANVILLE        True      False  1.424523e+10   \n",
       "3  2021-08-09 13:01:09        AOC        True      False  1.310860e+10   \n",
       "4  2021-07-17 16:28:47        AOC        True      False  1.310860e+10   \n",
       "\n",
       "   review_count  ...            city  \\\n",
       "0          1610  ...  West Hollywood   \n",
       "1          1610  ...  West Hollywood   \n",
       "2          1610  ...  West Hollywood   \n",
       "3          2362  ...     Los Angeles   \n",
       "4          2362  ...     Los Angeles   \n",
       "\n",
       "                                             address  \\\n",
       "0  ['8701 Beverly Blvd', 'West Hollywood, CA 90048']   \n",
       "1  ['8701 Beverly Blvd', 'West Hollywood, CA 90048']   \n",
       "2  ['8701 Beverly Blvd', 'West Hollywood, CA 90048']   \n",
       "3         ['8700 W 3rd St', 'Los Angeles, CA 90048']   \n",
       "4         ['8700 W 3rd St', 'Los Angeles, CA 90048']   \n",
       "\n",
       "                                      restaurant_url  \\\n",
       "0  https://www.yelp.com/biz/granville-west-hollyw...   \n",
       "1  https://www.yelp.com/biz/granville-west-hollyw...   \n",
       "2  https://www.yelp.com/biz/granville-west-hollyw...   \n",
       "3  https://www.yelp.com/biz/aoc-los-angeles?adjus...   \n",
       "4  https://www.yelp.com/biz/aoc-los-angeles?adjus...   \n",
       "\n",
       "                                           image_url   latitude   longitude  \\\n",
       "0  https://s3-media2.fl.yelpcdn.com/bphoto/EuQ6eU...  34.077130 -118.380680   \n",
       "1  https://s3-media2.fl.yelpcdn.com/bphoto/EuQ6eU...  34.077130 -118.380680   \n",
       "2  https://s3-media2.fl.yelpcdn.com/bphoto/EuQ6eU...  34.077130 -118.380680   \n",
       "3  https://s3-media4.fl.yelpcdn.com/bphoto/UGnsMC...  34.073416 -118.381928   \n",
       "4  https://s3-media4.fl.yelpcdn.com/bphoto/UGnsMC...  34.073416 -118.381928   \n",
       "\n",
       "                                              photos cross_streets Price  \\\n",
       "0  ['https://s3-media2.fl.yelpcdn.com/bphoto/EuQ6...           NaN     2   \n",
       "1  ['https://s3-media2.fl.yelpcdn.com/bphoto/EuQ6...           NaN     2   \n",
       "2  ['https://s3-media2.fl.yelpcdn.com/bphoto/EuQ6...           NaN     2   \n",
       "3  ['https://s3-media4.fl.yelpcdn.com/bphoto/UGns...           NaN     3   \n",
       "4  ['https://s3-media4.fl.yelpcdn.com/bphoto/UGns...           NaN     3   \n",
       "\n",
       "             City  \n",
       "0  West hollywood  \n",
       "1  West hollywood  \n",
       "2  West hollywood  \n",
       "3     Los angeles  \n",
       "4     Los angeles  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read review data\n",
    "review_df = pd.read_excel(r'E:\\LMU\\rmds_lab\\competition_2021\\Q3_competition\\sample_dashboard\\inputs\\Q3_competition_review_dataset.xlsx')\n",
    "\n",
    "# Merge together\n",
    "extended_df = review_df.merge(restaurant_df, left_on = 'id', right_on = 'id')\n",
    "extended_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pie Chart (Topic modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic modeling content following procedures in link below:\n",
    "# https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "\n",
    "# Feel free to apply other techniques in NLP or in other language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz (13.7 MB)\n",
      "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from en-core-web-sm==3.0.0) (3.0.7)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\anaconda_files\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (57.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.50.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.24.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.19.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.6.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.4.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.5 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n",
      "Requirement already satisfied: six in d:\\anaconda\\anaconda_files\\lib\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.15.0)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (5.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.7.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.4)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\anaconda\\anaconda_files\\lib\\site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\anaconda_files\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Install and import packages for topic modelling\n",
    "\n",
    "\n",
    "# Solution for some potential problems:\n",
    "# https://stackoverflow.com/questions/49964028/spacy-oserror-cant-find-model-en\n",
    "# https://github.com/explosion/spaCy/issues/7453\n",
    "!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz\n",
    "\n",
    "# Define all text in dataframe\n",
    "data = extended_df.review_text.values.tolist()\n",
    "\n",
    "# You might need to download stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "#print(stop_words)\n",
    "stop_words.extend(['nan', 'order','also','good','great', 'want','make','see','go','get','come','give','really','always',\n",
    "                  'usually', 'need', 'love', 'horrible','star', 'never','use','today','work','find','business','people',\n",
    "                  'awsome','worker','leave','plate','ever','amazing'])\n",
    "\n",
    "#Import libraries needed\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "import re\n",
    "from gensim.utils import simple_preprocess\n",
    "import spacy\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "    \n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove distracting single quotes\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_num</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>-7.593064</td>\n",
       "      <td>0.248111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>-7.666703</td>\n",
       "      <td>0.191943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>-7.722593</td>\n",
       "      <td>0.187518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>-7.779551</td>\n",
       "      <td>0.185313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_num  perplexity  coherence\n",
       "0          3   -7.593064   0.248111\n",
       "1          4   -7.666703   0.191943\n",
       "2          5   -7.722593   0.187518\n",
       "3          6   -7.779551   0.185313"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting model by tuning topic numbers\n",
    "topic_range=range(3,7,1)\n",
    "perplexity=[]\n",
    "coherence=[]\n",
    "topic_num=[]\n",
    "\n",
    "for i in topic_range:\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,id2word=id2word,random_state=100,update_every=1,chunksize=100,passes=10,\n",
    "                                           num_topics=i, alpha='auto',per_word_topics=True)\n",
    "                                           \n",
    "    topic_num.append(i)\n",
    "    perplexity.append(lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "    # Compute Coherence Score\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized , dictionary=id2word, coherence='c_v')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()    # higher the better\n",
    "    coherence.append(coherence_lda)  \n",
    "\n",
    "# Show performance for different topics\n",
    "# Could switch random seed to get different results\n",
    "data_dict={'topic_num':topic_num,'perplexity':perplexity,'coherence':coherence}\n",
    "performance_topic_num=pd.DataFrame(data_dict)\n",
    "performance_topic_num                                           \n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the model with 6 topics\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=6, \n",
    "                                           random_state=999,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=18,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3399</td>\n",
       "      <td>food, good, pizza, location, back, fry, even, ...</td>\n",
       "      <td>Slightly turned off by the hostess. She wasn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2587</td>\n",
       "      <td>order, chicken, get, taco, well, fresh, sandwi...</td>\n",
       "      <td>Wish I would have known about no brunch at the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2294</td>\n",
       "      <td>place, service, time, try, come, go, customer,...</td>\n",
       "      <td>I had an amazing experience at Granville.\\n\\nw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3535</td>\n",
       "      <td>food, good, pizza, location, back, fry, even, ...</td>\n",
       "      <td>Photo dump from dinner on Aug 8th. Literally c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3096</td>\n",
       "      <td>place, service, time, try, come, go, customer,...</td>\n",
       "      <td>I've had this place bookmarked on my Yelp for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32125</th>\n",
       "      <td>32125</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3005</td>\n",
       "      <td>place, service, time, try, come, go, customer,...</td>\n",
       "      <td>Horrible Horrible Horrible!!!!\\nI had heard so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32126</th>\n",
       "      <td>32126</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>place, service, time, try, come, go, customer,...</td>\n",
       "      <td>We stopped in after a trip to the desert.  Spl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32127</th>\n",
       "      <td>32127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3219</td>\n",
       "      <td>food, good, pizza, location, back, fry, even, ...</td>\n",
       "      <td>Updated hours are not true. Unable to order th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32128</th>\n",
       "      <td>32128</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2890</td>\n",
       "      <td>place, service, time, try, come, go, customer,...</td>\n",
       "      <td>Trash. Employees are very rude. Nobody there w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32129</th>\n",
       "      <td>32129</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3174</td>\n",
       "      <td>place, service, time, try, come, go, customer,...</td>\n",
       "      <td>If I could.give negative stars I would. This S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32130 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0                0             0.0              0.3399   \n",
       "1                1             5.0              0.2587   \n",
       "2                2             3.0              0.2294   \n",
       "3                3             0.0              0.3535   \n",
       "4                4             3.0              0.3096   \n",
       "...            ...             ...                 ...   \n",
       "32125        32125             3.0              0.3005   \n",
       "32126        32126             3.0              0.2364   \n",
       "32127        32127             0.0              0.3219   \n",
       "32128        32128             3.0              0.2890   \n",
       "32129        32129             3.0              0.3174   \n",
       "\n",
       "                                                Keywords  \\\n",
       "0      food, good, pizza, location, back, fry, even, ...   \n",
       "1      order, chicken, get, taco, well, fresh, sandwi...   \n",
       "2      place, service, time, try, come, go, customer,...   \n",
       "3      food, good, pizza, location, back, fry, even, ...   \n",
       "4      place, service, time, try, come, go, customer,...   \n",
       "...                                                  ...   \n",
       "32125  place, service, time, try, come, go, customer,...   \n",
       "32126  place, service, time, try, come, go, customer,...   \n",
       "32127  food, good, pizza, location, back, fry, even, ...   \n",
       "32128  place, service, time, try, come, go, customer,...   \n",
       "32129  place, service, time, try, come, go, customer,...   \n",
       "\n",
       "                                                    Text  \n",
       "0      Slightly turned off by the hostess. She wasn't...  \n",
       "1      Wish I would have known about no brunch at the...  \n",
       "2      I had an amazing experience at Granville.\\n\\nw...  \n",
       "3      Photo dump from dinner on Aug 8th. Literally c...  \n",
       "4      I've had this place bookmarked on my Yelp for ...  \n",
       "...                                                  ...  \n",
       "32125  Horrible Horrible Horrible!!!!\\nI had heard so...  \n",
       "32126  We stopped in after a trip to the desert.  Spl...  \n",
       "32127  Updated hours are not true. Unable to order th...  \n",
       "32128  Trash. Employees are very rude. Nobody there w...  \n",
       "32129  If I could.give negative stars I would. This S...  \n",
       "\n",
       "[32130 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel=lda_model, corpus=corpus,texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data)\n",
    "\n",
    "# Assign topics to text data\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "df_dominant_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['food, good, pizza, location, back, fry, even, taste, call, burger']\n",
      "['delicious, say, nice, spot, eat, restaurant, know, little, super, burrito']\n",
      "['take, year, favorite, new, close, last, drive, work, visit, keep']\n",
      "['place, service, time, try, come, go, customer, first, bad, staff']\n",
      "['wait, stop, long, minute, home, use, line, live, week, finally']\n",
      "['order, chicken, get, taco, well, fresh, sandwich, cheese, meat, decide']\n"
     ]
    }
   ],
   "source": [
    "#Print topics in job categories\n",
    "for n in range(6):\n",
    "  print(df_dominant_topic[df_dominant_topic['Dominant_Topic']==n]['Keywords'].unique())\n",
    "\n",
    "\n",
    "# Could go back to remove more stopwords after inspecting the key words below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorizing the key words into specific values cared by customers\n",
    "#0: Food\n",
    "#1: Environment\n",
    "#2: Experience\n",
    "#3: Service\n",
    "#4: Waiting time\n",
    "#5: Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace numbers with value names\n",
    "extended_df['Value']=df_dominant_topic.copy()['Dominant_Topic']\n",
    "\n",
    "extended_df['Value'].replace({0.0: 'Food', \n",
    "                              1.0: 'Environment',\n",
    "                              2.0: 'Experience',\n",
    "                              3.0: 'Service',\n",
    "                              4.0: 'Waiting time',\n",
    "                              5.0: 'Others'}, inplace=True)\n",
    "\n",
    "pie_df = extended_df[['review_id','categories01', 'categories02', 'categories03', 'City','Value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>categories01</th>\n",
       "      <th>categories02</th>\n",
       "      <th>categories03</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Value</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Environment</th>\n",
       "      <td>823</td>\n",
       "      <td>823</td>\n",
       "      <td>823</td>\n",
       "      <td>823</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experience</th>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Food</th>\n",
       "      <td>11044</td>\n",
       "      <td>11044</td>\n",
       "      <td>11044</td>\n",
       "      <td>11044</td>\n",
       "      <td>11044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Others</th>\n",
       "      <td>1842</td>\n",
       "      <td>1842</td>\n",
       "      <td>1842</td>\n",
       "      <td>1842</td>\n",
       "      <td>1842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Service</th>\n",
       "      <td>16911</td>\n",
       "      <td>18362</td>\n",
       "      <td>18362</td>\n",
       "      <td>18362</td>\n",
       "      <td>18362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waiting time</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              review_id  categories01  categories02  categories03   City\n",
       "Value                                                                   \n",
       "Environment         823           823           823           823    823\n",
       "Experience           57            57            57            57     57\n",
       "Food              11044         11044         11044         11044  11044\n",
       "Others             1842          1842          1842          1842   1842\n",
       "Service           16911         18362         18362         18362  18362\n",
       "Waiting time          2             2             2             2      2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See distribution in reviews topics\n",
    "\n",
    "pie_df.groupby('Value').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>time</th>\n",
       "      <th>weekday</th>\n",
       "      <th>review_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>West hollywood</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AyueC5Vq_5lUKJFqSzXWWw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>West hollywood</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yaH4AmHUz9b3Ywv4VtvU5g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>West hollywood</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>YiuFLFWsrP92_QWa-d2W2Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Los angeles</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>VyKvwjOuJxKWiLlyzsqQ_A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Los angeles</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>D0-MjyINO2u9IRmf1opaUQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             City  time  weekday               review_id\n",
       "0  West hollywood     1        1  AyueC5Vq_5lUKJFqSzXWWw\n",
       "1  West hollywood     1        1  yaH4AmHUz9b3Ywv4VtvU5g\n",
       "2  West hollywood     2        0  YiuFLFWsrP92_QWa-d2W2Q\n",
       "3     Los angeles     1        0  VyKvwjOuJxKWiLlyzsqQ_A\n",
       "4     Los angeles     1        5  D0-MjyINO2u9IRmf1opaUQ"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Organize review time values\n",
    "\n",
    "extended_df_drop = extended_df.copy()\n",
    "extended_df_drop = extended_df_drop.dropna(subset = ['review_time_created'])\n",
    "extended_df_drop['datetime'] = extended_df_drop['review_time_created'].apply(lambda x: parser.parse(str(x)))\n",
    "extended_df_drop['weekday'] = extended_df_drop['datetime'].apply(lambda x: x.timetuple()[6])\n",
    "extended_df_drop['time'] = extended_df_drop['datetime'].apply(lambda x: 3 if (x.timetuple()[3]>0  and x.timetuple()[3]<=6)\n",
    "                                                                else (0   if (x.timetuple()[3]>6  and x.timetuple()[3]<=12)\n",
    "                                                                else (1   if (x.timetuple()[3]>12 and x.timetuple()[3]<=18)\n",
    "                                                                else  2 \n",
    "                                                                     ))\n",
    "                                                             )\n",
    "\n",
    "heatmap_df = extended_df_drop[['City','time', 'weekday','review_id']]\n",
    "heatmap_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentiment scores\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "pol = lambda x: TextBlob(str(x)).sentiment.polarity\n",
    "extended_df['polarity'] = extended_df['review_text'].apply(pol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>GEOID10</th>\n",
       "      <th>COUNTYFP10</th>\n",
       "      <th>TRACTCE10</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>Acres</th>\n",
       "      <th>SqMi</th>\n",
       "      <th>Pop_16</th>\n",
       "      <th>Pop_Den</th>\n",
       "      <th>...</th>\n",
       "      <th>Other_Pct</th>\n",
       "      <th>NonWhite_P</th>\n",
       "      <th>Elders_Pct</th>\n",
       "      <th>SpksEng_Pc</th>\n",
       "      <th>UnEmp_Rate</th>\n",
       "      <th>Emp_15</th>\n",
       "      <th>Emp_Den</th>\n",
       "      <th>Income_Pct</th>\n",
       "      <th>Under19_Pc</th>\n",
       "      <th>MHI2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1578.707317</td>\n",
       "      <td>6.065791e+09</td>\n",
       "      <td>65.544715</td>\n",
       "      <td>246391.857724</td>\n",
       "      <td>91958.243902</td>\n",
       "      <td>88229.988551</td>\n",
       "      <td>137.859357</td>\n",
       "      <td>4490.983740</td>\n",
       "      <td>1230.174797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.037644</td>\n",
       "      <td>14.540244</td>\n",
       "      <td>80.168610</td>\n",
       "      <td>0.117539</td>\n",
       "      <td>1580.508130</td>\n",
       "      <td>350.921054</td>\n",
       "      <td>63684.211382</td>\n",
       "      <td>25.126423</td>\n",
       "      <td>75334.958159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acton</td>\n",
       "      <td>3666.000000</td>\n",
       "      <td>6.037911e+09</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>910804.500000</td>\n",
       "      <td>93510.000000</td>\n",
       "      <td>21652.935591</td>\n",
       "      <td>33.832711</td>\n",
       "      <td>3885.500000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.019941</td>\n",
       "      <td>13.650000</td>\n",
       "      <td>96.542727</td>\n",
       "      <td>0.142908</td>\n",
       "      <td>863.000000</td>\n",
       "      <td>25.697010</td>\n",
       "      <td>83423.500000</td>\n",
       "      <td>19.350000</td>\n",
       "      <td>88800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelanto</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>6.071009e+09</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>9114.000000</td>\n",
       "      <td>92301.000000</td>\n",
       "      <td>3208.159879</td>\n",
       "      <td>5.012750</td>\n",
       "      <td>8907.333333</td>\n",
       "      <td>2538.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.744861</td>\n",
       "      <td>7.233333</td>\n",
       "      <td>92.652833</td>\n",
       "      <td>0.283731</td>\n",
       "      <td>718.666667</td>\n",
       "      <td>166.954433</td>\n",
       "      <td>32950.333333</td>\n",
       "      <td>43.066667</td>\n",
       "      <td>30381.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agoura hills</td>\n",
       "      <td>2404.666667</td>\n",
       "      <td>6.037800e+09</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>800327.666667</td>\n",
       "      <td>91301.000000</td>\n",
       "      <td>1157.799864</td>\n",
       "      <td>1.809062</td>\n",
       "      <td>6286.000000</td>\n",
       "      <td>3642.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.625504</td>\n",
       "      <td>12.533333</td>\n",
       "      <td>96.928856</td>\n",
       "      <td>0.081204</td>\n",
       "      <td>2533.000000</td>\n",
       "      <td>1575.846109</td>\n",
       "      <td>116335.000000</td>\n",
       "      <td>25.700000</td>\n",
       "      <td>121158.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agua dulce</td>\n",
       "      <td>1640.000000</td>\n",
       "      <td>6.037911e+09</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>910813.000000</td>\n",
       "      <td>91390.000000</td>\n",
       "      <td>20384.572868</td>\n",
       "      <td>31.850895</td>\n",
       "      <td>3719.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.903643</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>99.295223</td>\n",
       "      <td>0.128446</td>\n",
       "      <td>697.000000</td>\n",
       "      <td>21.883215</td>\n",
       "      <td>97578.000000</td>\n",
       "      <td>19.700000</td>\n",
       "      <td>101220.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           city     OBJECTID       GEOID10  COUNTYFP10      TRACTCE10  \\\n",
       "0                1578.707317  6.065791e+09   65.544715  246391.857724   \n",
       "1         Acton  3666.000000  6.037911e+09   37.000000  910804.500000   \n",
       "2      Adelanto   640.000000  6.071009e+09   71.000000    9114.000000   \n",
       "3  Agoura hills  2404.666667  6.037800e+09   37.000000  800327.666667   \n",
       "4    Agua dulce  1640.000000  6.037911e+09   37.000000  910813.000000   \n",
       "\n",
       "            ZIP         Acres        SqMi       Pop_16      Pop_Den  ...  \\\n",
       "0  91958.243902  88229.988551  137.859357  4490.983740  1230.174797  ...   \n",
       "1  93510.000000  21652.935591   33.832711  3885.500000   115.000000  ...   \n",
       "2  92301.000000   3208.159879    5.012750  8907.333333  2538.000000  ...   \n",
       "3  91301.000000   1157.799864    1.809062  6286.000000  3642.666667  ...   \n",
       "4  91390.000000  20384.572868   31.850895  3719.000000   117.000000  ...   \n",
       "\n",
       "   Other_Pct  NonWhite_P  Elders_Pct  SpksEng_Pc  UnEmp_Rate       Emp_15  \\\n",
       "0        0.0   43.037644   14.540244   80.168610    0.117539  1580.508130   \n",
       "1        0.0   23.019941   13.650000   96.542727    0.142908   863.000000   \n",
       "2        0.0   82.744861    7.233333   92.652833    0.283731   718.666667   \n",
       "3        0.0   20.625504   12.533333   96.928856    0.081204  2533.000000   \n",
       "4        0.0   19.903643   16.700000   99.295223    0.128446   697.000000   \n",
       "\n",
       "       Emp_Den     Income_Pct  Under19_Pc        MHI2016  \n",
       "0   350.921054   63684.211382   25.126423   75334.958159  \n",
       "1    25.697010   83423.500000   19.350000   88800.000000  \n",
       "2   166.954433   32950.333333   43.066667   30381.000000  \n",
       "3  1575.846109  116335.000000   25.700000  121158.666667  \n",
       "4    21.883215   97578.000000   19.700000  101220.000000  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read population density and income data\n",
    "\n",
    "pop_des=pd.read_csv(r'E:\\LMU\\rmds_lab\\competition_2021\\Q3_competition\\sample_dashboard\\inputs\\population_density.csv')\n",
    "pop_des['Name'] = pop_des['name'].apply(lambda x: str(x).lower())\n",
    "pop_des['Name'] = pop_des['Name'].apply(lambda x: str(x)[0].upper()+ str(x)[1:])\n",
    "\n",
    "income=pd.read_csv(r'E:\\LMU\\rmds_lab\\competition_2021\\Q3_competition\\sample_dashboard\\inputs\\Median_Household_Income_(2016).csv')\n",
    "income['city'] = income['City_Name'].apply(lambda x: str(x).lower())\n",
    "income['city'] = income['city'].apply(lambda x: str(x)[0].upper()+ str(x)[1:])\n",
    "\n",
    "income_group = income.groupby('city').mean().reset_index()\n",
    "income_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>rating</th>\n",
       "      <th>Price</th>\n",
       "      <th>polarity</th>\n",
       "      <th>review_count</th>\n",
       "      <th>density</th>\n",
       "      <th>MHI2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agoura hills</td>\n",
       "      <td>3.859649</td>\n",
       "      <td>1.982456</td>\n",
       "      <td>0.237613</td>\n",
       "      <td>243.894737</td>\n",
       "      <td>982.1817</td>\n",
       "      <td>121158.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alhambra</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.171736</td>\n",
       "      <td>508.350000</td>\n",
       "      <td>4174.4164</td>\n",
       "      <td>55027.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arcadia</td>\n",
       "      <td>3.525773</td>\n",
       "      <td>1.845361</td>\n",
       "      <td>0.148571</td>\n",
       "      <td>309.958763</td>\n",
       "      <td>2016.1584</td>\n",
       "      <td>90598.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Artesia</td>\n",
       "      <td>3.714953</td>\n",
       "      <td>1.822430</td>\n",
       "      <td>0.198358</td>\n",
       "      <td>365.831776</td>\n",
       "      <td>3906.7655</td>\n",
       "      <td>57094.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Azusa</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042708</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2009.0266</td>\n",
       "      <td>60506.909091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           City    rating     Price  polarity  review_count    density  \\\n",
       "0  Agoura hills  3.859649  1.982456  0.237613    243.894737   982.1817   \n",
       "1      Alhambra  3.666667  1.800000  0.171736    508.350000  4174.4164   \n",
       "2       Arcadia  3.525773  1.845361  0.148571    309.958763  2016.1584   \n",
       "3       Artesia  3.714953  1.822430  0.198358    365.831776  3906.7655   \n",
       "4         Azusa  4.000000  1.000000  0.042708      3.000000  2009.0266   \n",
       "\n",
       "         MHI2016  \n",
       "0  121158.666667  \n",
       "1   55027.750000  \n",
       "2   90598.909091  \n",
       "3   57094.666667  \n",
       "4   60506.909091  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge data we need together (6 dimensions)\n",
    "\n",
    "df_pop_des = extended_df.merge(pop_des,left_on = 'City', right_on = 'Name')\n",
    "df_pop_des_inc = df_pop_des.merge(income_group,left_on = 'City', right_on = 'city')\n",
    "\n",
    "extended_df_radar = df_pop_des_inc[['City','rating','Price', 'polarity', 'review_count', 'density','MHI2016']].copy()\n",
    "extended_df_radar_group = extended_df_radar.groupby('City').mean().reset_index()\n",
    "extended_df_radar_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns and cut series to different scales\n",
    "\n",
    "extended_df_radar_group['rating_bin'] = pd.qcut(extended_df_radar_group['rating'],\n",
    "       5, labels=[1,2,3,4,5])\n",
    "extended_df_radar_group['price_bin'] = pd.qcut(extended_df_radar_group['Price'],\n",
    "       5, labels=[1,2,3,4,5])\n",
    "extended_df_radar_group['positiveness_bin'] = pd.qcut(extended_df_radar_group['polarity'],\n",
    "       5, labels=[1,2,3,4,5])\n",
    "extended_df_radar_group['review_num_bin'] = pd.qcut(extended_df_radar_group['review_count'],\n",
    "       5, labels=[1,2,3,4,5])\n",
    "extended_df_radar_group['population_density_bin'] = pd.qcut(extended_df_radar_group['density'],\n",
    "       5, labels=[1,2,3,4,5])\n",
    "extended_df_radar_group['income_bin'] = pd.qcut(extended_df_radar_group['MHI2016'],\n",
    "       5, labels=[1,2,3,4,5])\n",
    "\n",
    "radar_df= extended_df_radar_group[['City','rating_bin', 'price_bin','positiveness_bin','review_num_bin', 'population_density_bin', 'income_bin']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-fbd89aa8d49d>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  covid_la['datetime'] = covid_la['date'].apply(lambda x: date.fromisoformat(str(x)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['90802: Long Beach', '90803: Long Beach', '90804: Long Beach',\n",
       "       '90805: Long Beach', '90806: Long Beach', '90807: Long Beach',\n",
       "       '90808: Long Beach', '90810: Long Beach', '90813: Long Beach',\n",
       "       '90814: Long Beach', '90815: Long Beach', '91101: Pasadena',\n",
       "       '91103: Pasadena', '91104: Pasadena', '91105: Pasadena',\n",
       "       '91106: Pasadena', '91107: Pasadena', 'Agoura Hills', 'Alhambra',\n",
       "       'Arcadia', 'Artesia', 'Avalon', 'Azusa', 'Baldwin Park', 'Bell',\n",
       "       'Bell Gardens', 'Bellflower', 'Beverly Hills', 'Bradbury',\n",
       "       'Burbank', 'Calabasas', 'Carson', 'Cerritos', 'Claremont',\n",
       "       'Commerce', 'Compton', 'Covina', 'Cudahy', 'Culver City',\n",
       "       'Diamond Bar', 'Downey', 'Duarte', 'El Monte', 'El Segundo',\n",
       "       'Gardena', 'Glendale', 'Glendora', 'Hawaiian Gardens', 'Hawthorne',\n",
       "       'Hermosa Beach', 'Hidden Hills', 'Huntington Park', 'Industry',\n",
       "       'Inglewood', 'Irwindale', 'La Canada Flintridge',\n",
       "       'La Habra Heights', 'La Mirada', 'La Puente', 'La Verne',\n",
       "       'Lakewood', 'Lancaster', 'Lawndale', 'Lomita', 'Lynwood', 'Malibu',\n",
       "       'Manhattan Beach', 'Maywood', 'Monrovia', 'Montebello',\n",
       "       'Monterey Park', 'Norwalk', 'Palmdale', 'Palos Verdes Estates',\n",
       "       'Paramount', 'Pico Rivera', 'Pomona', 'Rancho Palos Verdes',\n",
       "       'Redondo Beach', 'Rolling Hills', 'Rolling Hills Estates',\n",
       "       'Rosemead', 'San Dimas', 'San Fernando', 'San Gabriel',\n",
       "       'San Marino', 'Santa Clarita', 'Santa Fe Springs', 'Santa Monica',\n",
       "       'Sierra Madre', 'Signal Hill', 'South El Monte', 'South Gate',\n",
       "       'South Pasadena', 'Temple City', 'Torrance', 'Vernon', 'Walnut',\n",
       "       'West Covina', 'West Hollywood', 'Westlake Village', 'Whittier',\n",
       "       'Adams-Normandie', 'Alsace', 'Angeles National Forest',\n",
       "       'Angelino Heights', 'Arleta', 'Atwater Village', 'Baldwin Hills',\n",
       "       'Bel Air', 'Beverly Crest', 'Beverlywood', 'Boyle Heights',\n",
       "       'Brentwood', 'Brookside', 'Cadillac-Corning', 'Canoga Park',\n",
       "       'Carthay', 'Central', 'Century City', 'Century Palms/Cove',\n",
       "       'Chatsworth', 'Cheviot Hills', 'Chinatown', 'Cloverdale/Cochran',\n",
       "       'Country Club Park', 'Crenshaw District', 'Crestview', 'Del Rey',\n",
       "       'Downtown', 'Eagle Rock', 'East Hollywood', 'Echo Park',\n",
       "       'El Sereno', 'Elysian Park', 'Elysian Valley', 'Encino',\n",
       "       'Exposition', 'Exposition Park', 'Faircrest Heights',\n",
       "       'Figueroa Park Square', 'Florence-Firestone', 'Glassell Park',\n",
       "       'Gramercy Place', 'Granada Hills', 'Green Meadows', 'Hancock Park',\n",
       "       'Harbor City', 'Harbor Gateway', 'Harbor Pines', 'Harvard Heights',\n",
       "       'Harvard Park', 'Highland Park', 'Historic Filipinotown',\n",
       "       'Hollywood', 'Hollywood Hills', 'Hyde Park', 'Jefferson Park',\n",
       "       'Koreatown', 'Lafayette Square', 'Lake Balboa', 'Lakeview Terrace',\n",
       "       'Leimert Park', 'Lincoln Heights', 'Little Armenia',\n",
       "       'Little Bangladesh', 'Little Tokyo', 'Longwood', 'Los Feliz',\n",
       "       'Manchester Square', 'Mandeville Canyon', 'Mar Vista',\n",
       "       'Marina Peninsula', 'Melrose', 'Mid-city', 'Miracle Mile',\n",
       "       'Mission Hills', 'Mt. Washington', 'North Hills',\n",
       "       'North Hollywood', 'Northridge', 'Pacific Palisades', 'Pacoima',\n",
       "       'Palisades Highlands', 'Palms', 'Panorama City', 'Park La Brea',\n",
       "       'Pico-Union', 'Playa Del Rey', 'Playa Vista', 'Porter Ranch',\n",
       "       'Rancho Park', 'Regent Square', 'Reseda', 'Reseda Ranch',\n",
       "       'Reynier Village', 'San Pedro', 'Shadow Hills', 'Sherman Oaks',\n",
       "       'Silver Lake', 'South Carthay', 'South Park', 'St Elmo Village',\n",
       "       'Studio City', 'Sun Valley', 'Sunland', 'Sycamore Square',\n",
       "       'Sylmar', 'Tarzana', 'Temple-Beaudry', 'Thai Town', 'Toluca Lake',\n",
       "       'Toluca Terrace', 'Toluca Woods', 'Tujunga', 'University Hills',\n",
       "       'University Park', 'Valley Glen', 'Valley Village', 'Van Nuys',\n",
       "       'Venice', 'Vermont Knolls', 'Vermont Square', 'Vermont Vista',\n",
       "       'Vernon Central', 'Victoria Park', 'View Heights', 'Watts',\n",
       "       'Wellington Square', 'West Adams', 'West Hills',\n",
       "       'West Los Angeles', 'West Vernon', 'Westchester', 'Westlake',\n",
       "       'Westwood', 'Wholesale District', 'Wilmington', 'Wilshire Center',\n",
       "       'Winnetka', 'Woodland Hills', 'Acton', 'Agua Dulce', 'Altadena',\n",
       "       'Anaverde', 'Unincorporated - Angeles National Forest',\n",
       "       'Unincorporated - Arcadia', 'Athens Village', 'Athens-Westmont',\n",
       "       'Avocado Heights', 'Unincorporated - Azusa', 'Bassett',\n",
       "       'Bouquet Canyon', 'Unincorporated - Bradbury', 'Canyon Country',\n",
       "       'Castaic', 'Unincorporated - Cerritos',\n",
       "       'Unincorporated - Claremont', 'Unincorporated - Covina',\n",
       "       'Covina (Charter Oak)', 'Del Aire', 'Unincorporated - Del Rey',\n",
       "       'Del Sur', 'Desert View Highlands', 'Unincorporated - Duarte',\n",
       "       'East Covina', 'East La Mirada', 'East Lancaster',\n",
       "       'East Los Angeles', 'East Pasadena', 'East Rancho Dominguez',\n",
       "       'East Whittier', 'El Camino Village', 'Unincorporated - El Monte',\n",
       "       'Elizabeth Lake', 'Unincorporated - Florence-Firestone',\n",
       "       'Franklin Canyon', 'Unincorporated - Glendora', 'Hacienda Heights',\n",
       "       'Unincorporated - Hawthorne', 'Hi Vista', 'Kagel/Lopez Canyons',\n",
       "       'La Crescenta-Montrose', 'Unincorporated - La Habra Heights',\n",
       "       'La Rambla', 'Unincorporated - La Verne', 'Ladera Heights',\n",
       "       'Lake Hughes', 'Lake Los Angeles', 'Lake Manor', 'Lennox',\n",
       "       'Leona Valley', 'Littlerock', 'Littlerock/Juniper Hills',\n",
       "       'Littlerock/Pearblossom', 'Llano', 'Marina del Rey',\n",
       "       'Unincorporated - Monrovia', 'Newhall', 'North Lancaster',\n",
       "       'North Whittier', 'Northeast San Gabriel', 'Padua Hills',\n",
       "       'Unincorporated - Palmdale', 'Palos Verdes Peninsula',\n",
       "       'Pearblossom/Llano', 'Pellissier Village', 'Placerita Canyon',\n",
       "       'Unincorporated - Pomona', 'Quartz Hill', 'Rancho Dominguez',\n",
       "       'Roosevelt', 'Rosewood', 'Rosewood/East Gardena',\n",
       "       'Rosewood/West Rancho Dominguez', 'Rowland Heights',\n",
       "       'San Francisquito Canyon/Bouquet Canyon', 'San Jose Hills',\n",
       "       'San Pasqual', 'Sand Canyon', 'Santa Catalina Island',\n",
       "       'Santa Monica Mountains', 'Saugus', 'Saugus/Canyon Country',\n",
       "       'South Antelope Valley', 'Unincorporated - South El Monte',\n",
       "       'South San Gabriel', 'South Whittier', 'Southeast Antelope Valley',\n",
       "       'Stevenson Ranch', 'Sun Village', 'Sunrise Village',\n",
       "       'Twin Lakes/Oat Mountain', 'Val Verde', 'Valencia', 'Valinda',\n",
       "       'View Park/Windsor Hills', 'Walnut Park', 'West Antelope Valley',\n",
       "       'West Carson', 'West Chatsworth', 'Unincorporated - West LA',\n",
       "       'West Puente Valley', 'West Rancho Dominguez',\n",
       "       'West Whittier/Los Nietos', 'Westfield/Academy Hills', 'Westhills',\n",
       "       'White Fence Farms', 'Unincorporated - Whittier',\n",
       "       'Whittier Narrows', 'Willowbrook', 'Wiseburn'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read covid data and cleaning for time and city columns\n",
    "\n",
    "covid = pd.read_csv(r'E:\\LMU\\rmds_lab\\competition_2021\\Q3_competition\\sample_dashboard\\inputs\\latimes-place-totals.csv')\n",
    "covid_la = covid[covid.county=='Los Angeles']\n",
    "covid_la['datetime'] = covid_la['date'].apply(lambda x: date.fromisoformat(str(x)))\n",
    "covid_la_2021 = covid_la[covid_la['datetime']>date.fromisoformat('2021-06-01')]\n",
    "covid_la_2021.name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-fefecbd68bcb>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  covid_la_2021['city'] = covid_la_2021.name.apply(lambda x: x.split(':')[-1].strip().lower())\n",
      "<ipython-input-22-fefecbd68bcb>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  covid_la_2021['city'] = covid_la_2021.city.apply(lambda x: str(x)[0].upper()+ str(x)[1:])\n"
     ]
    }
   ],
   "source": [
    "# Notice two large cities have smaller areas, we have to merge them into one\n",
    "\n",
    "covid_la_2021['city'] = covid_la_2021.name.apply(lambda x: x.split(':')[-1].strip().lower())\n",
    "covid_la_2021['city'] = covid_la_2021.city.apply(lambda x: str(x)[0].upper()+ str(x)[1:])\n",
    "\n",
    "covid_la_2021_pasadena = covid_la_2021[covid_la_2021['city']=='Pasadena'].groupby('datetime').sum().reset_index()\n",
    "covid_la_2021_pasadena['city']='Pasadena'\n",
    "covid_la_2021_lb = covid_la_2021[covid_la_2021['city']=='Long beach'].groupby('datetime').sum().reset_index()\n",
    "covid_la_2021_lb['city']='Long beach'\n",
    "\n",
    "covid_la_2021_rest = covid_la_2021[(covid_la_2021['city']!='Pasadena') & (covid_la_2021['city']!='Long beach')]\n",
    "covid_la_2021_rest_data = covid_la_2021_rest[['city','datetime','fips','confirmed_cases','population']].copy()\n",
    "\n",
    "# Now merge them back\n",
    "\n",
    "covid_la_2021_sub_all = pd.concat([covid_la_2021_lb,covid_la_2021_pasadena])\n",
    "covid_la_2021_all = pd.concat([covid_la_2021_sub_all,covid_la_2021_rest_data])\n",
    "covid_la_2021_all_select = covid_la_2021_all[covid_la_2021_all['city'].isin(city_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>fips</th>\n",
       "      <th>confirmed_cases</th>\n",
       "      <th>population</th>\n",
       "      <th>city</th>\n",
       "      <th>next_day_cases</th>\n",
       "      <th>new_daily_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-02</td>\n",
       "      <td>37</td>\n",
       "      <td>2688</td>\n",
       "      <td>34520.0</td>\n",
       "      <td>Beverly hills</td>\n",
       "      <td>2689.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-03</td>\n",
       "      <td>37</td>\n",
       "      <td>2689</td>\n",
       "      <td>34520.0</td>\n",
       "      <td>Beverly hills</td>\n",
       "      <td>2690.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-04</td>\n",
       "      <td>37</td>\n",
       "      <td>2690</td>\n",
       "      <td>34520.0</td>\n",
       "      <td>Beverly hills</td>\n",
       "      <td>2691.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-05</td>\n",
       "      <td>37</td>\n",
       "      <td>2691</td>\n",
       "      <td>34520.0</td>\n",
       "      <td>Beverly hills</td>\n",
       "      <td>2692.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-06</td>\n",
       "      <td>37</td>\n",
       "      <td>2692</td>\n",
       "      <td>34520.0</td>\n",
       "      <td>Beverly hills</td>\n",
       "      <td>2692.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     datetime  fips  confirmed_cases  population           city  \\\n",
       "0  2021-06-02    37             2688     34520.0  Beverly hills   \n",
       "1  2021-06-03    37             2689     34520.0  Beverly hills   \n",
       "2  2021-06-04    37             2690     34520.0  Beverly hills   \n",
       "3  2021-06-05    37             2691     34520.0  Beverly hills   \n",
       "4  2021-06-06    37             2692     34520.0  Beverly hills   \n",
       "\n",
       "   next_day_cases  new_daily_cases  \n",
       "0          2689.0              1.0  \n",
       "1          2690.0              1.0  \n",
       "2          2691.0              1.0  \n",
       "3          2692.0              1.0  \n",
       "4          2692.0              0.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get daily new cases per city and merge them back\n",
    "\n",
    "new_cases = pd.DataFrame(None)\n",
    "\n",
    "for city in covid_la_2021_all_select.city.unique():\n",
    "    temp_df = covid_la_2021_all_select[covid_la_2021_all_select['city'] == city]\n",
    "    temp_df = temp_df.sort_values(by='datetime')\n",
    "    temp_df['next_day_cases']  = temp_df['confirmed_cases'].shift(-1)\n",
    "    new_cases = pd.concat([temp_df, new_cases])\n",
    "\n",
    "new_cases['new_daily_cases'] = new_cases['next_day_cases'] - new_cases['confirmed_cases']\n",
    "new_cases = new_cases[new_cases['new_daily_cases']>=0]\n",
    "\n",
    "line_df = new_cases.sort_values(by=['city','datetime']).reset_index().drop('index',axis=1)\n",
    "line_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the style from the link:\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "# Embed the style to the dashabord:\n",
    "app = dash.Dash(__name__, external_stylesheets=external_stylesheets)\n",
    "#app = dash.Dash(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.layout = html.Div([\n",
    "    html.H2(children=\"Restaurant Analytical Dashboard\"),\n",
    "    \n",
    "    # Set up Dropdown\n",
    "    dcc.Dropdown(id='dpdn1', value='Chinese', multi=False, \n",
    "                 options=[{'label': x, 'value': x} for x in category_list]),\n",
    "\n",
    "    html.Div([dcc.Graph(id='map-graph', figure={}, className='five columns'),\n",
    "              dcc.Graph(id='pie-graph', figure={}, className='three columns'),\n",
    "              dcc.Graph(id='bar-graph', figure={}, className='three columns')\n",
    "             ]),\n",
    "    \n",
    "    dcc.Dropdown(id='dpdn2', value=['Long beach','Pasadena'], multi=True, \n",
    "                 options=[{'label': x, 'value': x} for x in city_list]),\n",
    "    \n",
    "    html.Div([dcc.Graph(id='heatmap-graph', figure={}, className='five columns'), \n",
    "              dcc.Graph(id='radar-graph', figure={}, className='three columns'),\n",
    "              dcc.Graph(id='line-graph', figure={}, className='three columns')\n",
    "             ]),\n",
    "    \n",
    "    # Set up some end notes\n",
    "    html.H2(children= 'Produced by RMDS Lab for 2021 Q3 Competition'),\n",
    "    \n",
    "    dcc.Link(children= 'See Competition Page    &   ', href = 'https://grmds.org/Q3/Comp', target = 'https://grmds.org/Q3/Comp'),\n",
    "    \n",
    "    dcc.Link(children= 'RMDS Covid Risk Map', href = 'https://grmds.org/risk/', target = 'https://grmds.org/risk/')\n",
    "\n",
    "], style={\"text-align\": \"center\"})\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "\n",
    "# Output graphs with input from dropdown\n",
    "\n",
    "@app.callback(\n",
    "    Output(component_id='map-graph', component_property='figure'),\n",
    "    Input(component_id='dpdn1', component_property='value'),\n",
    ")\n",
    "\n",
    "\n",
    "def update_map(category):\n",
    "    \n",
    "    if category == 0:\n",
    "        select_df_1 = map_df\n",
    "    else:\n",
    "        select_df_1 = map_df[(map_df['categories01']==category) | \n",
    "                             (map_df['categories02']==category) | \n",
    "                             (map_df['categories03']==category)\n",
    "                            ]\n",
    "    \n",
    "    select_df_1['Rating'] = select_df_1['rating']\n",
    "    \n",
    "    chart1 = px.scatter_mapbox(select_df_1, lat=\"latitude\", lon=\"longitude\", color=\"Rating\", size=\"Price\", \n",
    "                               title='Where Are the Restaurants? <br> Geographic Distribution',\n",
    "                               color_continuous_scale=px.colors.cyclical.IceFire, size_max=6, zoom=8,\n",
    "                               mapbox_style=\"carto-positron\", width=600, height =500 ) \n",
    "    chart1.update(layout=dict(title=dict(x=0.5)))\n",
    "    \n",
    "    return chart1\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(component_id='pie-graph', component_property='figure'),\n",
    "    Input(component_id='dpdn1', component_property='value'),\n",
    ")\n",
    "\n",
    "# Change chart when received diffrent inputs\n",
    "def update_pie(category):\n",
    "    if category == 0:\n",
    "        select_df_2 = pie_df\n",
    "    else:\n",
    "        select_df_2 = pie_df[(pie_df['categories01']==category) | \n",
    "                             (pie_df['categories02']==category) | \n",
    "                             (pie_df['categories03']==category)\n",
    "                            ]\n",
    "        \n",
    "    chart2= px.pie(\n",
    "                data_frame=select_df_2,\n",
    "                values =select_df_2.groupby('Value')['City'].count().sort_values(ascending=False)[:10],\n",
    "                title='What Concerns Reviewers? <br> Review Topics', \n",
    "                names=select_df_2.groupby('Value').count().sort_values(by='City',ascending=False).index[:10],\n",
    "                hole=.3,\n",
    "                color_discrete_sequence=px.colors.qualitative.G10,\n",
    "                width=400, height =500\n",
    "                )\n",
    "\n",
    "    chart2.update(layout=dict(title=dict(x=0.5)))    \n",
    "    \n",
    "    return chart2\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "@app.callback(\n",
    "    Output(component_id='bar-graph', component_property='figure'),\n",
    "    Input(component_id='dpdn1', component_property='value'),\n",
    ")    \n",
    "def update_bar(category):\n",
    "    \n",
    "    if category == 0:\n",
    "        select_df_3 = bar_df\n",
    "    else:\n",
    "        select_df_3 = bar_df[(bar_df['categories01']==category) | \n",
    "                             (bar_df['categories02']==category) | \n",
    "                             (bar_df['categories03']==category)\n",
    "                            ]\n",
    "         \n",
    "    chart3 = px.bar(y=select_df_3.groupby('price')['review_count'].mean(),\n",
    "                    title='How many Reviews? <br> #Reviews by $ Level', \n",
    "                    x=select_df_3.groupby('price')['review_count'].mean().index,\n",
    "                    width=500, height=500\n",
    "                   )\n",
    "    \n",
    "    chart3.update(layout=dict(title=dict(x=0.5)))\n",
    "    chart3.update_layout(xaxis_title=\"Price Level\", yaxis_title=\"Average Reviews\")\n",
    "    \n",
    "    return chart3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(component_id='heatmap-graph', component_property='figure'),\n",
    "    Input(component_id='dpdn2', component_property='value'),\n",
    ")\n",
    "def update_heatmap(cityname):\n",
    "    \n",
    "    #Create a pivot table\n",
    "    local_df = heatmap_df[heatmap_df['City'].isin(cityname)]\n",
    "    local_df_clean = local_df[['time', 'weekday','review_id']]\n",
    "    local_df_pivot = local_df_clean.pivot_table(index = 'time', columns='weekday', aggfunc='count')\n",
    "\n",
    "    chart4 = px.imshow(local_df_pivot,\n",
    "                       width=600, height =500, \n",
    "                       title = 'When Do They Post Reviews? <br> Review Frequency',\n",
    "                       labels=dict(x=\"Weekday\", y=\"Time\", color=\"#Review\"),\n",
    "                                   x=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday','Sunday'],\n",
    "                                   y=['Morning', 'Afternoon', 'Evening', 'Night']\n",
    "                                  )\n",
    "    chart4.update_xaxes(side=\"bottom\")\n",
    "    chart4.update(layout=dict(title=dict(x=0.5)))\n",
    "\n",
    "    return chart4\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(component_id='radar-graph', component_property='figure'),\n",
    "    Input(component_id='dpdn2', component_property='value'),\n",
    ")\n",
    "def update_radar(cityname):\n",
    "    \n",
    "    local_df_2 = radar_df[radar_df['City'].isin(cityname)]\n",
    "    local_df_2.columns= ['City', 'Rating', 'Price', '+Review', '#Review', 'Pop Density', 'Income']\n",
    "    local_df_2_stacked = local_df_2.set_index('City').stack().reset_index()\n",
    "\n",
    "    chart5 = px.line_polar(local_df_2_stacked, r=0, theta=\"level_1\", color=\"City\", line_close=True,\n",
    "                           width=400, height =500, \n",
    "                           title = 'How Does Your City Compare? <br>City Comparability',\n",
    "                           color_discrete_sequence=px.colors.qualitative.G10)\n",
    "    chart5.update(layout=dict(title=dict(x=0.5)))\n",
    "\n",
    "    return chart5\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(component_id='line-graph', component_property='figure'),\n",
    "    Input(component_id='dpdn2', component_property='value'),\n",
    ")\n",
    "def update_line(cityname):\n",
    "    \n",
    "    local_df_3 = line_df[line_df['city'].isin(cityname)]\n",
    "    \n",
    "    local_df_3['Date'] = local_df_3['datetime']\n",
    "    local_df_3['New confirmed cases'] = local_df_3['new_daily_cases']\n",
    "    local_df_3['City'] = local_df_3['city']\n",
    "\n",
    "    chart6 = px.line(local_df_3, x='Date', y='New confirmed cases',\n",
    "                     color='City', title='Is COVID Affecting Your City? <br> COVID Outbreak by City',\n",
    "                    width=500, height =500, color_discrete_sequence=px.colors.qualitative.G10)\n",
    "    \n",
    "    chart6.update_xaxes(side=\"bottom\")\n",
    "    chart6.update(layout=dict(title=dict(x=0.5)))\n",
    "    \n",
    "    return chart6\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [03/Sep/2021 11:48:57] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [03/Sep/2021 11:48:59] \"\u001b[37mGET /_dash-component-suites/dash_html_components/dash_html_components.v1_1_4m1629313584.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [03/Sep/2021 11:48:59] \"\u001b[37mGET /_dash-component-suites/dash/deps/prop-types@15.v1_21_0m1629313585.7.2.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [03/Sep/2021 11:48:59] \"\u001b[37mGET /_dash-component-suites/dash/deps/react-dom@16.v1_21_0m1629313585.14.0.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [03/Sep/2021 11:48:59] \"\u001b[37mGET /_dash-component-suites/dash/deps/react@16.v1_21_0m1629313585.14.0.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [03/Sep/2021 11:48:59] \"\u001b[37mGET /_dash-component-suites/dash_core_components/dash_core_components-shared.v1_17_1m1629313583.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [03/Sep/2021 11:48:59] \"\u001b[37mGET /_dash-component-suites/dash/deps/polyfill@7.v1_21_0m1629313585.12.1.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [03/Sep/2021 11:48:59] \"\u001b[37mGET /_dash-component-suites/dash/dash-renderer/build/dash_renderer.v1_21_0m1629313585.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [03/Sep/2021 11:48:59] \"\u001b[37mGET /_dash-component-suites/dash_core_components/dash_core_components.v1_17_1m1629313583.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [03/Sep/2021 11:48:59] \"\u001b[37mGET /_dash-layout HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [03/Sep/2021 11:48:59] \"\u001b[37mGET /_dash-dependencies HTTP/1.1\u001b[0m\" 200 -\n",
      "<ipython-input-25-fdc1933a1583>:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  select_df_1['Rating'] = select_df_1['rating']\n",
      "127.0.0.1 - - [03/Sep/2021 11:49:00] \"\u001b[37mGET /_dash-component-suites/dash_core_components/async-dropdown.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [03/Sep/2021 11:49:00] \"\u001b[37mGET /_dash-component-suites/dash_core_components/async-graph.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [03/Sep/2021 11:49:00] \"\u001b[37mGET /_dash-component-suites/dash_core_components/async-plotlyjs.js HTTP/1.1\u001b[0m\" 200 -\n",
      "<ipython-input-25-fdc1933a1583>:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  local_df_3['Date'] = local_df_3['datetime']\n",
      "<ipython-input-25-fdc1933a1583>:180: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  local_df_3['New confirmed cases'] = local_df_3['new_daily_cases']\n",
      "<ipython-input-25-fdc1933a1583>:181: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  local_df_3['City'] = local_df_3['city']\n",
      "127.0.0.1 - - [03/Sep/2021 11:49:15] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [03/Sep/2021 11:49:16] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [03/Sep/2021 11:49:16] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [03/Sep/2021 11:49:16] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [03/Sep/2021 11:49:16] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [03/Sep/2021 11:49:16] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app.run_server()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
